{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, our Imports, the given functions and some global variables!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "first_l=0\n",
    "first_r=0\n",
    "rho = 1 # distance resolution in pixels of the Hough grid\n",
    "theta = np.pi/180 # angular resolution in radians of the Hough grid\n",
    "threshold = 3     # minimum number of votes (intersections in Hough grid cell)\n",
    "min_line_length = 5 #minimum number of pixels making up a line\n",
    "max_line_gap = 1    # maximum gap in pixels between connectable line segments\n",
    "\n",
    "filteredp3=[]    # list for the filter of the left lane\n",
    "filteredp4=[]    # list for the filter of the right lane\n",
    "\n",
    "def grayscale(img):\n",
    "    \"\"\"Applies the Grayscale transform\n",
    "    This will return an image with only one color channel\n",
    "    but NOTE: to see the returned image as grayscale\n",
    "    you should call plt.imshow(gray, cmap='gray')\"\"\"\n",
    "    return cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # Or use BGR2GRAY if you read an image with cv2.imread()\n",
    "    # return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "def canny(img, low_threshold, high_threshold):\n",
    "    \"\"\"Applies the Canny transform\"\"\"\n",
    "    return cv2.Canny(img, low_threshold, high_threshold)\n",
    "\n",
    "def gaussian_blur(img, kernel_size):\n",
    "    \"\"\"Applies a Gaussian Noise kernel\"\"\"\n",
    "    return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)\n",
    "\n",
    "def region_of_interest(img, vertices):\n",
    "    \"\"\"\n",
    "    Applies an image mask.\n",
    "    \n",
    "    Only keeps the region of the image defined by the polygon\n",
    "    formed from `vertices`. The rest of the image is set to black.\n",
    "    \"\"\"\n",
    "    #defining a blank mask to start with\n",
    "    mask = np.zeros_like(img)   \n",
    "    \n",
    "    #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "        \n",
    "    #filling pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    \n",
    "    #returning the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Draw Lines \n",
    "In Drawlines, firstly I divide the line points into two groups, that one set\n",
    "has the points in the half left region defined by the vertices and the other in the other half right.\n",
    "Moreover the points are checked if they are within a minimum distance on the x axis\n",
    "from the previously tracked lane. The minimum distance starts from a smaller value for the points\n",
    "near the top of the lane and becomes bigger in the bottom of the image. This comes from the fact \n",
    "that a bump will result in a bigger change on the x axis for the bottom than from the middle of the image\n",
    "for the line tracked. Last but not least, the angle of the points is checked to be within the desirable limits. \n",
    "\n",
    "In addition, the tangent of their angles is checked if it is within a good limit\n",
    "Left: lines_l_x, lines_l_y\n",
    "Right: lines_r_y, lines_r_y\n",
    "\n",
    "Then, I approximate the lanes by a 1st degree polynomial approximation on the two \n",
    "sets of lists.\n",
    "\n",
    "Then I use a median filter for the angle and constants of the two lines:\n",
    "Y=aX+b   a=median_filter(order 5)\n",
    "         b=median_filter(order 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#Median filter for angles\n",
    "def medfilt_a(arr):\n",
    "    sum=0\n",
    "    for each in arr:\n",
    "        sum+=each[0]\n",
    "    return sum/len(arr)\n",
    "\n",
    "#Median filter for constants\n",
    "def medfilt_b(arr):\n",
    "    sum=0\n",
    "    for each in arr:\n",
    "        sum+=each[1]\n",
    "    return sum/len(arr)\n",
    "\n",
    "def draw_lines(img, lines, color=[255, 0, 0], thickness=2):\n",
    "    global first_l\n",
    "    global first_r\n",
    "    global filteredp3\n",
    "    global filteredp4\n",
    "\n",
    "    lines_l_x=[]\n",
    "    lines_l_y=[]\n",
    "\n",
    "    lines_r_x=[]\n",
    "    lines_r_y=[]\n",
    "\n",
    "    lastp4=[0,0]\n",
    "    imshape=img.shape\n",
    "    thres=imshape[1]/2\n",
    "    th=10\n",
    "    distance=25\n",
    "    \n",
    "    #Seperate Points in Left and Right group\n",
    "    #constraints:\n",
    "    #a) 0.7<(tangent(angle) < 2\n",
    "    #b) distance from last lane approximation < distance+2*distance*(y-2*Ymax/3)/(Ymax/3) \n",
    "    for line in lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "          if( abs((x2-x1)/(y2-y1))>0.7 and abs((x2-x1)/(y2-y1))<2 ):\n",
    "           if(first_l==0):\n",
    "             if(x1<thres and x2<thres):\n",
    "               lines_l_x.append(x1)\n",
    "               lines_l_x.append(x2)\n",
    "               lines_l_y.append(y1)\n",
    "               lines_l_y.append(y2) \n",
    "           else:\n",
    "             if(x1<thres and x1<thres):\n",
    "               lastp3=filteredp3[0]\n",
    "               lastp3[0]=medfilt_a(filteredp3)\n",
    "               lastp3[1]=medfilt_b(filteredp3)\n",
    "               if(abs(int(lastp3(y1)-y1))<(distance+2*distance*(y1-2*imshape[0]/3)/(imshape[0]/3)) and\n",
    "                  abs(int(lastp3(y2)-x2))<(distance+2*distance*(y1-2*imshape[0]/3)/(imshape[0]/3))):\n",
    "                  lines_l_x.append(x1)\n",
    "                  lines_l_x.append(x2)\n",
    "                  lines_l_y.append(y1)\n",
    "                  lines_l_y.append(y2)\n",
    "           if(first_r==0):\n",
    "             if(x1>thres and x2>thres):\n",
    "               lines_r_x.append(x1)\n",
    "               lines_r_x.append(x2)\n",
    "               lines_r_y.append(y1)\n",
    "               lines_r_y.append(y2)\n",
    "           else:\n",
    "             if(x1>thres and x2>thres):\n",
    "               lastp4=filteredp4[0]\n",
    "               lastp4[0]=medfilt_a(filteredp4)\n",
    "               lastp4[1]=medfilt_b(filteredp4)\n",
    "               if(abs(int(lastp4(y1)-x1))<(distance+2*distance*(y1-2*imshape[0]/3)/(imshape[0]/3)) and \n",
    "                  abs(int(lastp4(y2)-x2))<(distance+2*distance*(y1-2*imshape[0]/3)/(imshape[0]/3))):\n",
    "                  lines_r_x.append(x1)\n",
    "                  lines_r_x.append(x2)\n",
    "                  lines_r_y.append(y1)\n",
    "                  lines_r_y.append(y2)\n",
    "\n",
    "    if(len(lines_l_x)>0):\n",
    "       z3 = np.polyfit( lines_l_y,lines_l_x, 1)\n",
    "       p3 = np.poly1d(z3)\n",
    "       if(len(filteredp3)==0):\n",
    "           filteredp3.append(p3)\n",
    "           first_l=1\n",
    "       else:\n",
    "           filteredp3.append(p3)\n",
    "           p3[0]=medfilt_a(filteredp3)\n",
    "           p3[1]=medfilt_b(filteredp3)\n",
    "       cv2.line(img,(int(p3(2*imshape[0]/3)),int(2*imshape[0]/3)), ( int(p3(imshape[0])) ,int(imshape[0]) ), color, thickness=th)\n",
    "    elif( len(filteredp3)>=1):\n",
    "       #Safety case : no points are extracted! use last approximation\n",
    "       p3=filteredp3[0]\n",
    "       p3[0]=medfilt_a(filteredp3)\n",
    "       p3[1]=medfilt_b(filteredp3)\n",
    "       cv2.line(img,(int(p3(2*imshape[0]/3)),int(2*imshape[0]/3)), ( int(p3(imshape[0])) ,int(imshape[0]) ), color, thickness=th)\n",
    "\n",
    "    #Keep only 5 items for the filter\n",
    "    if(len(filteredp3)==5): \n",
    "       del filteredp3[0]\n",
    "\n",
    "    if(len(lines_r_x)>0):\n",
    "       z4 = np.polyfit( lines_r_y,lines_r_x, 1)\n",
    "       p4 = np.poly1d(z4)\n",
    "       if( len(lines_r_x)==0):\n",
    "           filteredp4.append(p4)\n",
    "           first_r=1\n",
    "       else:\n",
    "           filteredp4.append(p4)\n",
    "           p4[0]=medfilt_a(filteredp4)\n",
    "           p4[1]=medfilt_b(filteredp4)\n",
    "       cv2.line(img,(int(p4(2*imshape[0]/3)),int((2*imshape[0]/3))), (int(p4(imshape[0])),int(imshape[0])), color, thickness=th)\n",
    "    elif( len(filteredp4)>=1):\n",
    "       #Safety case : no points are extracted! use last approximation\n",
    "       p4=filteredp4[0]\n",
    "       p4[0]=medfilt_a(filteredp4)\n",
    "       p4[1]=medfilt_b(filteredp4)\n",
    "       cv2.line(img,(int(p4(2*imshape[0]/3)),int((2*imshape[0]/3))), (int(p4(imshape[0])),int(imshape[0])), color, thickness=th)\n",
    "    \n",
    "    #Keep only 5 items for the filter\n",
    "    if(len(filteredp4)==5):\n",
    "       del filteredp4[0]\n",
    "\n",
    "def hough_lines(img, rho, theta, threshold, min_line_len, max_line_gap):\n",
    "    \"\"\"\n",
    "    `img` should be the output of a Canny transform.\n",
    "        \n",
    "    Returns an image with hough lines drawn.\n",
    "    \"\"\"\n",
    "    lines = cv2.HoughLinesP(img, rho, theta, threshold, np.array([]), minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    "    line_img = np.zeros((*img.shape, 3), dtype=np.uint8)\n",
    "    draw_lines(line_img, lines)\n",
    "    return line_img\n",
    "\n",
    "# Python 3 has support for cool math symbols.\n",
    "\n",
    "def weighted_img(img, initial_img, α=0.8, β=1., λ=0.):\n",
    "    \"\"\"\n",
    "    `img` is the output of the hough_lines(), An image with lines drawn on it.\n",
    "    Should be a blank image (all black) with lines drawn on it.\n",
    "    \n",
    "    `initial_img` should be the image before any processing.\n",
    "    \n",
    "    The result image is computed as follows:\n",
    "    \n",
    "    initial_img * α + img * β + λ\n",
    "    NOTE: initial_img and img must be the same shape!\n",
    "    \"\"\"\n",
    "    return cv2.addWeighted(initial_img, α, img, β, λ)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Findlane \n",
    "The main tricks here are:\n",
    "\n",
    "a)The vertices of the region of interest is defined on proportion to the image axis sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def findlane(image):\n",
    "    imshape=image.shape\n",
    "    gray=grayscale(image)\n",
    "    gray_blur=gaussian_blur(image,7)\n",
    "    edges = cv2.Canny(gray_blur, 100, 250)\n",
    "    vertices = np.array([[(imshape[1]/8,int(imshape[0])),(imshape[1]/2-imshape[1]/6, 2*imshape[0]/3), \n",
    "                          (imshape[1]/2+imshape[1]/6, 2*imshape[0]/3), (7*imshape[1]/8+50,int(imshape[0]))]],\n",
    "                        dtype=np.int32)\n",
    "    roi=region_of_interest(edges,vertices)\n",
    "    line_image = np.copy(image)*0 # creating a blank to draw lines on\n",
    "    lines = hough_lines(roi, rho, theta, threshold, min_line_length, max_line_gap)\n",
    "    color_edges = np.dstack((edges, edges, edges)) \n",
    "    lines_edges = cv2.addWeighted( image, 0.8,lines, 1, 0) \n",
    "    return lines_edges\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def process_image(image):\n",
    "    # NOTE: The output you return should be a color image (3 channel) for processing video below\n",
    "    # TODO: put your pipeline here,\n",
    "    # you should return the final output (image with lines are drawn on lanes)\n",
    "\n",
    "    return findlane(image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's Test it!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video white.mp4\n",
      "[MoviePy] Writing video white.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 221/222 [00:12<00:00, 17.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: white.mp4 \n",
      "\n",
      "CPU times: user 1min 15s, sys: 3.63 s, total: 1min 18s\n",
      "Wall time: 13.2 s\n"
     ]
    }
   ],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "first_l=0\n",
    "first_r=0\n",
    "filteredp3=[]\n",
    "filteredp4=[] \n",
    "white_output = 'white.mp4'\n",
    "clip1 = VideoFileClip(\"solidWhiteRight.mp4\")\n",
    "white_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"white.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(white_output)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video yellow.mp4\n",
      "[MoviePy] Writing video yellow.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 681/682 [00:40<00:00, 17.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: yellow.mp4 \n",
      "\n",
      "CPU times: user 3min 53s, sys: 11.4 s, total: 4min 4s\n",
      "Wall time: 40.8 s\n"
     ]
    }
   ],
   "source": [
    "first_l=0\n",
    "first_r=0\n",
    "filteredp3=[]\n",
    "filteredp4=[] \n",
    "yellow_output = 'yellow.mp4'\n",
    "clip2 = VideoFileClip('solidYellowLeft.mp4')\n",
    "yellow_clip = clip2.fl_image(process_image)\n",
    "%time yellow_clip.write_videofile(yellow_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"yellow.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(yellow_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video extra.mp4\n",
      "[MoviePy] Writing video extra.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 251/251 [00:26<00:00,  9.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: extra.mp4 \n",
      "\n",
      "CPU times: user 2min 18s, sys: 6.8 s, total: 2min 25s\n",
      "Wall time: 27.3 s\n"
     ]
    }
   ],
   "source": [
    "first_l=0\n",
    "first_r=0\n",
    "filteredp3=[]\n",
    "filteredp4=[] \n",
    "extra= 'extra.mp4'\n",
    "clip3 = VideoFileClip('challenge.mp4')\n",
    "yellow_clip = clip3.fl_image(process_image)\n",
    "%time yellow_clip.write_videofile(extra, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"extra.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(extra))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improvements \n",
    "\n",
    "\n",
    "1)Better Filter:\n",
    "\n",
    "   A butterworth filter might be better in following immediate true changes like when bumps occur.\n",
    "   \n",
    "2)Bump detection function to help Filter weight the latest change value more than the past. \n",
    "\n",
    "3)More Test videos are required to experiment on the parameters like tangent(angle) limits, blurring,\n",
    "  can\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
